{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyfair\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfair.report.individual import FairReport\n",
    "from pyfair.report.tree_graph import FairTreeGraph\n",
    "from pyfair.report.exceedence import FairExceedenceCurves\n",
    "from pyfair.utility.beta_pert import FairBetaPert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1 = pyfair.FairModel(name=\"HA\", n_simulations=10_000)\n",
    "model1.input_data('Loss Event Frequency', low=.01, mode=.2, high=.5)\n",
    "model1.input_data('Probable Loss Magnitude', low=1, mode=1_000_000, high=60_000_000)\n",
    "model1.calculate_all()\n",
    "\n",
    "model2 = pyfair.FairModel(name=\"HA2\", n_simulations=10_000)\n",
    "model2.input_data('Loss Event Frequency', low=.1, mode=.2, high=.9)\n",
    "model2.input_data('Probable Loss Magnitude', low=1, mode=1_000_000, high=90_000_000)\n",
    "model2.calculate_all()\n",
    "\n",
    "model3 = pyfair.FairModel(name=\"HA3\", n_simulations=10_000)\n",
    "model3.input_data('Loss Event Frequency', low=.1, mode=.2, high=.3, constant=.5)\n",
    "model3.input_data('Probable Loss Magnitude', low=5, mode=5, high=10)\n",
    "model3.calculate_all()\n",
    "\n",
    "\n",
    "#fr = FairReport(model1)\n",
    "#fr.to_html('C:/Users/theon/Desktop/report.html')\n",
    "results = model1.export_results()\n",
    "node_statuses = model1.get_node_statuses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b0a7dc4b1322>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ha'"
     ]
    }
   ],
   "source": [
    "d = dict()\n",
    "d.setdefault(None)\n",
    "\n",
    "d['ha']\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 288x36 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x26ec176fdd8>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAA6CAYAAAC00zwaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAAzBJREFUeJzt3bFrXlUcxvHvY2o7atRFVDBCl44dpJMIQltcsjhksrh0UP8AnYr1P3AqggV1sBWnDIoUHJysuiitUIx1MCg4RLoISuTn8P4KIebNe3m5Jb7N9wOX3Pecc8+9gZwn595zSVJVSNIDB30Bkv4fDANJgGEgqRkGkgDDQFIzDCQBcGTEvlyjlA5GxuhkzDC4Z5K3/lNWdeEArkS6f3mbIAkwDCQ1w0ASYBhIaoaBJMAwkNQMA0mAYSCpLcRLR1oce70gBr4ktgicGUgCDANJzTCQBBgGkpphIAkwDCQ1w0AScIjeM7jX69+ur+uuRf1ZcGYgCTAMJDXDQBJgGEhqhoEkwDCQ1AwDSYBhIKmlapz/ipbkfFW9O0pnkgYba+yNOTM4P2JfkoYbZex5myAJMAwktTHDwOcF0sEYZeyN9gBR0mLzNkESMDAMkpxNcivJRpI39qg/luRq119P8vSOuje7/FaSM+NdunR/S3I5ye9JbkypT5J3enx9n+TkjrpzSX7s7dygE1bVvhuwBPwEPAMcBb4DTuxq8ypwqffXgKu9f6LbHwNWup+lWed0c3MrgOeAk8CNKfUvAp8BAU4B17v8EeB2f13u/eVZ5xsyM3gW2Kiq21X1N3AFWN3VZhV4v/c/AV5Iki6/UlV/VdXPwEb3J2mGqvoS2NqnySrwQU18BTyc5HHgDHCtqraq6g/gGnB21vmGhMETwC87Pm922Z5tqmobuAM8OvBYSfOZNr7mGndDwiB7lO1egpjWZsixkuYz6rgbEgabwFM7Pj8J/DqtTZIjwENMpjdDjpU0n2nja65xNyQMvgGOJ1lJcpTJA8L1XW3WgbtPLF8CvqjJk4x1YK1XG1aA48DXA84pabZ14OVeVTgF3Kmq34DPgdNJlpMsA6e7bF8z/1R6VW0neb07WwIuV9XNJBeBb6tqHXgP+DDJBpMZwVofezPJx8APwDbwWlX9M8c3LR06ST4CngceS7IJXAAeBKiqS8CnTFYUNoA/gVe6bivJ20x+kQNcrKr9HkROztdLEZIOOd9AlAQYBpKaYSAJMAwkNcNAEmAYSGqGgSTAMJDU/gWQdnlqORZ48gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyfair.report.base_curve import FairBaseCurve\n",
    "\n",
    "\n",
    "class FairDistributionCurve(FairBaseCurve):\n",
    "    '''A shiny distribution curve to lend credibility to our guesstimates.'''\n",
    "    \n",
    "    def __init__(self, model_or_iterable):\n",
    "        self._input = self._input_check(model_or_iterable)\n",
    "    \n",
    "    def generate_image(self):\n",
    "        pass\n",
    "    \n",
    "    def _generate_icon(self, data):\n",
    "        fig, ax = plt.subplots(figsize=(4, .5))\n",
    "        # For each model, calculate and plot.\n",
    "        plt.hist(data, bins=30, color='navy')\n",
    "        ax.set_xlim(0, data.max())\n",
    "        # Tweak ticks based on content\n",
    "        if data.max() <= 1:\n",
    "            ax.axes.xaxis.set_major_formatter(matplotlib.ticker.StrMethodFormatter('{x:,.2f}'))\n",
    "            plt.xticks([0, 1])\n",
    "        else:\n",
    "            ax.axes.xaxis.set_major_formatter(matplotlib.ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "            plt.xticks([0, data.max()])\n",
    "        # Set spines and axis invisible\n",
    "        for spine in ['left', 'right', 'top', 'bottom']:\n",
    "            ax.spines[spine].set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        return (fig, ax)\n",
    "    \n",
    "    \n",
    "    def generate_icons(self):\n",
    "        '''Get a dictionary of miniature histogram figures'''\n",
    "        # Setup plots\n",
    "        pass\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "fdc = FairDistributionCurve([model1, model2])\n",
    "fdc._generate_icon(pd.Series([.1,.2,.3,.6,.1,.6,.9,.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpc = FairExceedenceCurves([model1, model2])\n",
    "fig1, ax1 = fpc.generate_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.T\n",
    "rep = FairReport(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(model1)\n",
    "\n",
    "hasattr(object, '__iter__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "from pyfair.model.model import FairModel\n",
    "from pyfair.model.meta_model import FairMetaModel\n",
    "from pyfair.utility.fair_exception import FairException\n",
    "\n",
    "\n",
    "class FairExceedenceCurves(object):\n",
    "    '''Plots one or more exceedence curves'''\n",
    "    \n",
    "    def __init__(self, model_or_iterable):\n",
    "        # If it's just a model, make it a list.\n",
    "        self._input = self._input_check(model_or_iterable)\n",
    "\n",
    "    def _input_check(self, value):\n",
    "        # If it's a model or metamodel, plug it in a dict.\n",
    "        rv = {}\n",
    "        if value.__class__.__name__ in ['FairModel', 'FairMetaModel']:\n",
    "            rv[value.get_name()] = value\n",
    "            return rv\n",
    "        # Check for iterable.\n",
    "        if not hasattr(value, '__iter__'):\n",
    "            raise FairException('Input is not a FairModel, FairMetaModel, or an iterable.')\n",
    "        # Iterate and process remainder.\n",
    "        for proported_model in value:\n",
    "            if proported_model.__class__.__name__ in ['FairModel', 'FairMetaModel']:\n",
    "                rv[proported_model.get_name()] = proported_model\n",
    "            else:\n",
    "                raise FairException('Iterable member is not a FairModel or FairMetaModel')\n",
    "        return rv\n",
    "    \n",
    "    def generate_image(self):\n",
    "        '''Main function for generating plots'''\n",
    "        # Setup plots\n",
    "        fig, axes = plt.subplots(2,1, figsize=(6, 8))\n",
    "        plt.subplots_adjust(hspace=.5)\n",
    "        ax1, ax2 = axes\n",
    "        # For each model, calculate and plot.\n",
    "        for name, model in self._input.items():\n",
    "            data = model.export_results()\n",
    "            # Get Risk Data\n",
    "            risk = data['Risk']\n",
    "            risk_max = risk.max()\n",
    "            # Create feature space\n",
    "            space = pd.Series(np.linspace(0, risk_max, 100))\n",
    "            # Get X and Y for each calculation\n",
    "            prob_xy = self._get_prob_data(space, risk)\n",
    "            loss_xy = self._get_loss_data(space, risk)\n",
    "            # Generate curves with x and y\n",
    "            self._generate_prob_curve(name, ax1, *prob_xy)\n",
    "            self._generate_loss_curve(name, ax2, *loss_xy)\n",
    "        return (fig, (ax1, ax2))\n",
    "    \n",
    "    def _get_prob_data(self, space, risk):\n",
    "        '''Get the percentle score for each risk value'''\n",
    "        quantiles = space.map(lambda x: stats.percentileofscore(risk, x))\n",
    "        return (quantiles, space)\n",
    "    \n",
    "    def _get_loss_data(self, space, risk):\n",
    "        '''Get percentage of values under loss value for each value'''\n",
    "        loss_ex = space.map(lambda value: (value < risk).mean())\n",
    "        return (space, loss_ex * 100)    \n",
    "        \n",
    "    def _generate_prob_curve(self, name, ax, quantiles, space):\n",
    "        '''For each percentile, what is the expected loss?'''\n",
    "        # Plot\n",
    "        ax.plot(quantiles, space)\n",
    "        # Style\n",
    "        ax.axes.yaxis.set_major_formatter(matplotlib.ticker.StrMethodFormatter('${x:,.0f}'))\n",
    "        ax.axes.xaxis.set_major_formatter(matplotlib.ticker.StrMethodFormatter('{x:,.0f}%'))\n",
    "        ax.axes.set_title('Exceedence Probability Curve', fontsize=20)\n",
    "        ax.legend(name, frameon=False)\n",
    "    \n",
    "    def _generate_loss_curve(self, name, ax, space, loss_expectancy):\n",
    "        '''For each dollar amount, what was the probability that loss was exceeded?'''\n",
    "        # Plot\n",
    "        ax.plot(space, loss_expectancy)\n",
    "        # Style\n",
    "        ax.axes.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}%'))\n",
    "        ax.axes.xaxis.set_major_formatter(StrMethodFormatter('${x:,.0f}'))\n",
    "        ax.axes.xaxis.set_tick_params(rotation=-45)\n",
    "        for tick in ax.axes.xaxis.get_major_ticks():\n",
    "            tick.label.set_horizontalalignment('left')\n",
    "        ax.axes.set_title('Loss Exceedence Curve', fontsize=20)\n",
    "        ax.legend(name, frameon=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpc = FairExceedenceCurves([model1, model2])\n",
    "fig1, ax1 = fpc.generate_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r = model1.export_results()\n",
    "p = model1.export_params()\n",
    "\n",
    "risk = r['Risk']\n",
    "risk_min = risk.min()\n",
    "risk_max = risk.max()\n",
    "\n",
    "# Loss Exceedence Curbe\n",
    "space = np.linspace(0, risk_max, 100)\n",
    "series = pd.Series(space)\n",
    "quantiles = series.map(lambda x: stats.percentileofscore(risk, x))\n",
    "ax = plt.plot(quantiles, series)[0]\n",
    "\n",
    "xax = ax.axes.xaxis\n",
    "yax = ax.axes.yaxis\n",
    "\n",
    "yax.set_major_formatter(matplotlib.ticker.StrMethodFormatter('${x:,.0f}'))\n",
    "xax.set_major_formatter(matplotlib.ticker.StrMethodFormatter('{x:,.0f}%'))\n",
    "\n",
    "ax.axes.set_title('Exceedence Probability Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each point dollar amount, the probability it was exceeded\n",
    "fbp = FairBetaPert(low=20_000_000, high=100_000_000, mode=23_000_000)\n",
    "rand = fbp.random_variates(100_000)\n",
    "\n",
    "space = np.linspace(0, rand.max(), 100)\n",
    "series = pd.Series(space)\n",
    "loss_ex = series.map(lambda value: (value < rand).mean())\n",
    "ax = plt.plot(space, loss_ex * 100)[0]\n",
    "\n",
    "xax = ax.axes.xaxis\n",
    "yax = ax.axes.yaxis\n",
    "\n",
    "xax.set_major_formatter(matplotlib.ticker.StrMethodFormatter('${x:,.0f}'))\n",
    "yax.set_major_formatter(matplotlib.ticker.StrMethodFormatter('{x:,.0f}%'))\n",
    "\n",
    "xax.set_tick_params(rotation=-45)\n",
    "for tick in xax.get_major_ticks():\n",
    "    tick.label.set_horizontalalignment('left')\n",
    "    \n",
    "ax.axes.set_title('Loss Exceedence Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pyfair.FairModel(name=\"HA\", n_simulations=10_000)\n",
    "model1.input_data('Loss Event Frequency', low=.01, mode=.2, high=.5)\n",
    "model1.input_data('Probable Loss Magnitude', low=1, mode=1_000_000, high=10_000_000)\n",
    "model1.calculate_all()\n",
    "\n",
    "model2 = pyfair.FairModel(name=\"NOT HA\", n_simulations=10_000)\n",
    "model2.input_data('Loss Event Frequency', low=.01, mode=.2, high=.5)\n",
    "model2.input_data('Probable Loss Magnitude', low=1, mode=1_000_000, high=10_000_000)\n",
    "model2.calculate_all()\n",
    "\n",
    "\n",
    "meta1 = pyfair.FairMetaModel('Metamodel', [model1, model2])\n",
    "out_json = pyfair.FairMetaModel('Metamodel2', [model1, meta1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(type(meta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FairModel\n",
    "    Just one\n",
    "FairAddititveMetaModel\n",
    "    Add all the risks together and display with components\n",
    "FairComparativeMetaModel\n",
    "    Put risks side by side\n",
    "    \n",
    "Mu, Sigma for Risk\n",
    "\n",
    "Model Params\n",
    "\n",
    "Source\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.Series(\n",
    "    {\n",
    "        'Author': os.environ['USERNAME'],\n",
    "        'Generated': str(pd.datetime.now()).partition('.')[0],\n",
    "        'PyFair Version': pyfair.VERSION\n",
    "    }\n",
    ").to_frame()\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Left third, provided data. RIght 2/3rds, tree\n",
    "model2 = pyfair.read_json(results)\n",
    "params = model2.export_params()\n",
    "data = model2.export_results()\n",
    "del params['Creation Datetime']\n",
    "df = pd.DataFrame.from_dict(params)\n",
    "df = df.reindex(['low', 'mode', 'high', 'p'])\n",
    "df.index = df.index.str.title()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived = df.agg([np.mean, np.std, np.min, np.max])\n",
    "derived.index = ['μ', 'σ', 'Minimum', 'Maximum']\n",
    "\n",
    "final_data = pd.concat([derived, df], axis=0)\n",
    "final_data = final_data.dropna()\n",
    "\n",
    "# If Column as data greater than 1,\n",
    "condition = final_data.max() > 1\n",
    "\n",
    "# Get True Clumns\n",
    "true_col = condition.loc[condition].index.values\n",
    "\n",
    "#Get False COlumns\n",
    "false_col = condition.loc[~condition].index.values\n",
    "\n",
    "# If false, it's between 0 and 1. 3 decimals\n",
    "final_data[false_col] = final_data[false_col]\n",
    "final_data[false_col] = final_data[false_col].applymap(lambda x: '{0:.3f}'.format(x))\n",
    "\n",
    "# If true, get the max digits and round\n",
    "final_data[true_col] = final_data[true_col].astype(int)\n",
    "final_data[true_col] = final_data[true_col].applymap(lambda x: '{0:,}'.format(x))\n",
    "\n",
    "for column in ['Probable Loss Magnitude', 'Risk']:\n",
    "    if column in final_data.columns:\n",
    "        final_data[column] = '$' + final_data[column]\n",
    "\n",
    "final_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = pyfair.read_json(results)\n",
    "df3 = model3.export_results()\n",
    "risk = df3['Risk']\n",
    "risk_d = risk.agg([np.mean, np.std, np.min, np.max]).astype(int)\n",
    "risk_d.index = ['μ', 'σ', 'Minimum', 'Maximum']\n",
    "\n",
    "pd.DataFrame(risk_d).T.applymap(lambda x: '${0:,}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw curves?\n",
    "model3.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SINGLE\n",
    "    header\n",
    "    meta\n",
    "    left third, risk top then params. right 2/3, tree diagram\n",
    "    left have loss excedence, right half exceedence probability\n",
    "    code\n",
    "    \n",
    "COMPARISON\n",
    "    header\n",
    "    meta\n",
    "    left third, risk top then params for each. right 2/3, tree diagram\n",
    "    left have loss excedence, right half exceedence probability\n",
    "    code\n",
    "\n",
    "ADDITIVE\n",
    "    header\n",
    "    meta\n",
    "    for each:\n",
    "        left third, risk top then params. right 2/3, tree diagram\n",
    "        left have loss excedence, right half exceedence probability\n",
    "    for all:\n",
    "        loss exceedence and exceedence probability and \n",
    "        risk\n",
    "    code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairBasic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "td = tempfile.mkdtemp()\n",
    "tf = tempfile.NamedTemporaryFile(dir=td, mode='w+')\n",
    "os.chdir(td)\n",
    "\n",
    "tf.write('LATEX!')\n",
    "\n",
    "os.listdir(td)\n",
    "\n",
    "p = subprocess.run(['dir', str(td)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
